---
title: "R stats for nutrition binary logistic regression"
author: "Alex German"
date: "18 June 2022"
output:
  pdf_document: default
  word_document: default
  html_notebook: default
  html_document:
    df_print: paged
---


# Create data frame for analysis
### NB need to run "Read_data_101.Rtm" first to create dataset
```{r include=FALSE}
knitr::knit("Read_data_101.rmd")
```


# LET'S DO SOME INTIAL TABULATION AND CHI SQUARE TESTS

## Tabulate D_Sex + D_Neuter + D_Diet
```{r 1}
## three way cross tabs (xtabs) and flatten the table
ftable(xtabs(~ D_Sex + D_Neuter + D_Diet, data = ml))
```

## Tabulate D_Neuter + D_Diet
```{r 2}
## two way cross tabs (xtabs) and flatten the table
ftable(xtabs(~ D_Neuter + D_Diet, data = ml))
```

## Tabulate C_Diet_Vegan + D_Diet_Vegan
```{r 3}
## two way cross tabs (xtabs) and flatten the table
ftable(xtabs(~ C_Diet_Vegan + D_Diet_Vegan, data = ml))
```

## Tabulate C_Diet_Vegan_Veggie + D_Diet_Vegan_Veggie
```{r 4}
## two way cross tabs (xtabs) and flatten the table
ftable(xtabs(~ C_Diet_Vegan_Veggie + D_Diet_Vegan_Veggie, data = ml))
```

## Tabulate D_Sex, D_Neuter and D_Raw
```{r 5}
## three way cross tabs (xtabs) and flatten the table
ftable(xtabs(~ D_Sex + D_Neuter + D_Diet_Raw, data = ml))
```


# Tabulate D_Neuter and D_Raw
```{r 6}
## two way cross tabs (xtabs) and flatten the table
ftable(xtabs(~ D_Neuter + D_Diet_Raw, data = ml))
```


## Chi squared test of C_VEGAN vs D-VEGAN
```{r 7}

table(ml$C_Diet_Vegan, ml$D_Diet_Vegan)
chisq.test(ml$C_Diet_Vegan, ml$D_Diet_Vegan, correct=FALSE)
```


## Chi squared test of NEUTERED vs D-RAW
```{r 8}

table(ml$D_Neuter, ml$D_Diet_Raw)
chisq.test(ml$D_Neuter, ml$D_Diet_Raw, correct=FALSE)
```



## Tabulate Health_Binary and Income
```{r I57}
## three way cross tabs (xtabs) and flatten the table
ftable(xtabs(~ Health_Binary + Income, data = ml))
```

## Chi squared test of Health_Binary and Income
```{r I58}

table(ml$Health_Binary, ml$Income)
chisq.test(ml$Health_Binary, ml$Income, correct=FALSE)
```




# BINARY LOGISTIC REGRESSION ON HEALTH

# CHECK EFFECT OF OWNER CHARACTERISTICS - simple binary logistic regression


## CLIENT DIET Binary regression for Any_Health_Problem
```{r 9g}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ C_Diet, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 9ag}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r 10g}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 11g}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 12g}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 13g}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## CLIENT DIET VEGAN Binary regression for Any_Health_Problem
```{r 9}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ C_Diet_Vegan, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 9a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r 10}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 11}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 12}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

# Filter potential influential data points with abs(.std.res) > 3:
```{r 13}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## C_Diet_Vegan_Veggie Binary logistic regression for HEALTH
```{r I84}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ C_Diet_Vegan_Veggie, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I84a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I85}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I86}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I87}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I88}
model.data %>% 
  filter(abs(.std.resid) > 3)
```





## LOCATION binary logistic regression for HEALTH
```{r I9}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Location, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
glmtoolbox::hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I9a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I10}
plot(m, which = 4, id.n = 3)
```

# Extract model results and display data for top 3 values using Cook's distance
```{r I11}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I12}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I13}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## SETTING binary logistic regression for HEALTH
```{r I14}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ setting, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
glmtoolbox::hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I14a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I15}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I16}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I17}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I18}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## URBAN binary logistic regression for HEALTH
```{r I19}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Urban, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I19a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I20}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I21}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I22}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I23}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## Location + URBAN binary logistic regression for HEALTH
```{r I24}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Location + Urban, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I24a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I25}
plot(m, which = 4, id.n = 3)
```

# Extract model results and display data for top 3 values using Cook's distance
```{r I26}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I27}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I28}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r I29}
car::vif(m)
```



## LOCATION * URBAN binary logistic regression for HEALTH
```{r I30}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Location*Urban, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I30a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I31}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I32}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I33}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I34}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

# check for multicollinearity
```{r I35}
car::vif(m)
```



## EDUCATION Binary logistic regression for HEALTH
```{r I37}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Education, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```
### Calculate Nagelkerke R^2
```{r I37a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I38}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I39}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I40}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

# Filter potential influential data points with abs(.std.res) > 3:
```{r I41}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## EDUCATION_S Binary logistic regression for HEALTH
```{r I42}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Education_S, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=3)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I42a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I43}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I44}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I45}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I46}
model.data %>% 
  filter(abs(.std.resid) > 3)
```


## EDUCATION_S Binary logistic regression for HEALTH
```{r I42i}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Education_S2, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=3)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I42ai}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I43i}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I44i}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I45i}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I46i}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## ANIMAL CAREER 2 Binary logistic regression for HEALTH
```{r I47}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Animal_Career2, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I47a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I48}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I49}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I50}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I51}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## ANIMAL_CAREER_BINARY Binary logistic regression for HEALTH
```{r I52}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Animal_Career_BINARY, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I52a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I53}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I54}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I55}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I56}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## INCOME Binary logistic regression for HEALTH
```{r I59}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Income, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
glmtoolbox::hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I59a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I60}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I61}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I62}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I63}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## INCOME2 Binary logistic regression for HEALTH
```{r I59i}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Income2, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
glmtoolbox::hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I59ai}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I60i}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I61i}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I62i}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I63i}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## C_AGE Binary logistic regression for HEALTH
```{r I64}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ C_Age, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=4)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I64a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I65}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I66}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I67}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I68}
model.data %>% 
  filter(abs(.std.resid) > 3)
```


## C_AGE Binary logistic regression for HEALTH
```{r I64i}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ C_Age2, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=4)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I64ai}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I65i}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I66i}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I67i}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I68i}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## C_GENDER Binary logistic regression for HEALTH
```{r I69}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ C_Gender, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I69a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I70}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I71}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I72}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I73}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



# NOW CHECK ASSOCIATIONS WITH DOG CHARACTERISTICS - simple BINARY LOGISTIC regression


## DOG DIET ordinal regression for HEALTH
```{r 14i}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ D_Diet, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 14ai}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r 15i}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 16i}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 17i}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 18i}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## DOG DIET VEGAN ordinal regression for HEALTH
```{r 14}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ D_Diet_Vegan, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 14a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r 15}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 16}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 17}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 18}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## CLIENT DIET VEGAN + DOG DIET VEGAN ordinal regression for HEALTH
```{r 19}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ C_Diet_Vegan + D_Diet_Vegan, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 19a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r 20}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 21}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 22}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 23}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r 24}
car::vif(m)
```



## CLIENT DIET VEGAN * DOG DIET VEGAN ordinal regression for HEALTH
```{r 25}
# fit binary logit model and store results 'm2'
m <- glm(Any_Health_Problem ~ C_Diet_Vegan*D_Diet_Vegan, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
glmtoolbox::hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 25a}
NagelkerkeR2(m)
```


### check assumptions of model
#### Cook's distance
```{r 26}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 27}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 28}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 29}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r 30}
car::vif(m)
```



## DOG DIET RAW ordinal regression for HEALTH
```{r 32}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ D_Diet_Raw, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 32a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r 33}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 34}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 35}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 36}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## DOG DIET + CLIENT DIET binary logistic regression for HEALTH
```{r 78}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ D_Diet + C_Diet , data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=7)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 78a}
NagelkerkeR2(m)
```


### check assumptions of model
#### Cook's distance
```{r 79}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 80}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 81}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 82}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r 89}
car::vif(m)
```




## THERAPEUTIC DIET binary logistic regression for HEALTH
```{r 90}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Therapeutic_Food, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 90a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r 91}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 92}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 93}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 94}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## DOG DIET + THERAPEUTIC DIET binary logistic regression for HEALTH
```{r 95}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ D_Diet + Therapeutic_Food, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=3)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 95a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r 96}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 97}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 98}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 99}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r I1}
car::vif(m)
```



## DOG DIET * THERAPEUTIC DIET binary logistic regression for HEALTH
```{r I2}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ D_Diet*Therapeutic_Food, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=7)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I2a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I3}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I4}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I6}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I7}
model.data %>% 
  filter(abs(.std.resid) > 3)
```


#### check for multicollinearity
#### Note interactions
```{r I8}
car::vif(m)
```


## SIZE Binary logistic regression for HEALTH
```{r I89}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Size, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### check assumptions of model
#### Cook's distance
```{r I90}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I91}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I92}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I93}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## SIZE2 Binary logistic regression for HEALTH
```{r I89ii}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Size2, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I89iiia}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I90ii}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I91ii}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I92ii}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I93ii}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## SIZE_GIANT Binary logistic regression for HEALTH
```{r I89iii}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Size_Giant, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I90iiia}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I90iii}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I91iii}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I92iii}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I93iii}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## D_AGE Binary logistic regression for HEALTH
```{r I94}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ D_Age, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I94a}
NagelkerkeR2(m)
```

### Check age is linear with logit of outcome
#### Note lack of linearity
```{r I95}
ypred = predict(m)
res = residuals(m, type = 'deviance')
plot(ypred,res)
```


### Box Tidwell test to check that D_Age is linearly associated with the logit of the outcome
#### suggests not linear
```{r I96}
boxTidwell(ml$Health_Binary ~ ml$D_Age)
```

### check assumptions of model
#### Cook's distance
```{r I97}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I98}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I99}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I100}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## D_Age_quant logistic regression for HEALTH
#### Note better model fit than D-Age
```{r II1}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ D_Age_quant, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=4)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II1aa}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II1a}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II2}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II3}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II4}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## DOG SEX binary logistic regression for HEALTH
```{r 37g}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ D_Sex, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 37ag}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r 38g}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 39g}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 40g}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 41g}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## DOG NEUTER binary logistic regression for HEALTH
```{r 37}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ D_Neuter, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 37a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r 38}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 39}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 40}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 41}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## D_Sex + D_Neuter Binary logistic regression for HEALTH
```{r II5}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ D_Sex + D_Neuter, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II5a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II6}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II7}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II8}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II9}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II10}
car::vif(m)
```



## D_Sex * D_Neuter Binary logistic regression for HEALTH
```{r II11}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ D_Sex*D_Neuter, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II11a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II12}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II13}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II14}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II15}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II16}
car::vif(m)
```


# CHECK EFFECT OF DOG HEALTH CHARACTERISTICS - simple binary regression

## THERAPEUTIC FOOD Binary logistic regression for HEALTH
```{r II27}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Therapeutic_Food, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II27a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II28}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II29}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II30}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II31}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## VISITS Binary logistic regression for HEALTH
```{r II32}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Visits, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II32a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II33}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II34}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II35}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II36}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## VISITS2 Binary logistic regression for HEALTH
#### Note Visits better fit than Visits2
```{r II37}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Visits2, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II37a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II37aa}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II38}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II39}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II40}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## MEDS Binary logistic regression for HEALTH
```{r II41}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II41a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II42}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II43}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II44}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

# Filter potential influential data points with abs(.std.res) > 3:
```{r II45}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
## ROUND 1a: All models of significance on simple regression
#### D_Age included as quantiles and Animal Career as a binary
#### Income education, C_Age and Size included as factor not ordered
```{r II46u}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Location + C_Age2 + Size2 + D_Diet + Therapeutic_Food + Animal_Career_BINARY + C_Gender +
         + C_Diet + D_Age_quant + D_Neuter + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II46au}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II47u}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II48u}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II49u}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II50u}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II51u}
car::vif(m)
```













# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
## ROUND 1b: Location removed as was lwast significant in round 1a.
```{r II46}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ C_Age2 + Size2 + D_Diet + Therapeutic_Food + Animal_Career_BINARY + C_Gender +
         + C_Diet + D_Age_quant + D_Neuter + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II46a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II47}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II48}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II49}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II50}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II51}
car::vif(m)
```



# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
## ROUND 2: Remove C_Diet as least significant variable in round 1
```{r II52}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ C_Age2 + Size2 + D_Diet + Therapeutic_Food + Animal_Career_BINARY + C_Gender +
         + D_Age_quant + D_Neuter + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II52a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II53}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II54}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II55}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II56}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II57}
car::vif(m)
```



# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
## ROUND 3: Remove D_Neuter as least significant variable in round 2
```{r II58}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ C_Age2 + Size2 + D_Diet + Therapeutic_Food + Animal_Career_BINARY + C_Gender +
         + D_Age_quant + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II58a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II59}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II60}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II61}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II62}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II63}
car::vif(m)
```



# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
## ROUND 4: Remove Animal_Career-Binary as least significant variable in round 3
```{r II64}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ C_Age2 + Size2 + D_Diet + Therapeutic_Food + C_Gender +
         + D_Age_quant + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II64a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II65}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II66}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II67}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II68}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II68a}
car::vif(m)
```



# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
## ROUND 5: Remove C_Gender as least significant variable in round 4
```{r II69}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ C_Age2 + Size2 + D_Diet + Therapeutic_Food +
         + D_Age_quant + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```
### Calculate Nagelkerke R^2
```{r II69a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II70}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II71}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II72}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II73}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II74}
car::vif(m)
```



# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
## ROUND 6: Remove Size2 as least significant variable in round 5
#### Model fit improved when C-Gender removed.
### Next, try removing Size2
```{r II75}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ C_Age2 + Therapeutic_Food  + 
         + D_Age_quant + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=9)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II75a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II76}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II77}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II78}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II79}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II80}
car::vif(m)
```



# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
## Round 6 part 2.  try without D_Diet
#### NB model fit improved dramatically when Size2 removed
#### Now try without D_Diet
```{r II81}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ C_Age2 + Therapeutic_Food  +
         + D_Age_quant + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II81a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II82}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II83}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II84}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II85}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II86}
car::vif(m)
```



# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
## Round 6 part 3.
#### D_Diet removal neither improves nor worsens the model.  retain for now.
#### Now try without C_Age2 instead
```{r II81iii}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ D_Diet + Therapeutic_Food  +
         + D_Age_quant + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II81aiii}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II82iii}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II83iii}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II84iii}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II85iii}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II86iii}
car::vif(m)
```



# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
## Round 6 part 4.
#### Fit is better without C_Age
#### Try removing D_Diet again.
```{r II81iv}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ D_Diet + Therapeutic_Food  +
         + D_Age_quant + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II81aiv}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II82iv}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II83iv}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II84iv}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II85iv}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II86v}
car::vif(m)
```



# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
## ROUND 7
#### Again, D_Diet does not improve the model. 
#### Now Try interactions between age and Visits
```{r II81ii}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~  Therapeutic_Food  +
         + D_Age_quant + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II81aii}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II82ii}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II83ii}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II84ii}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II85ii}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II86ii}
car::vif(m)
```



# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
## ROUND 8: Now try interactions between age and Meds
```{r II87}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Therapeutic_Food 
         + D_Age_quant*Meds + Visits, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II87a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II88}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II89}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II90}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II91}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II92}
car::vif(m)
```



# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
## ROUND 9: Try interaction between meds and Therapeutic diet
```{r II93}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Therapeutic_Food*Meds 
         + D_Age_quant + Visits, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II93a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II94}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II95}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II96}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II97}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II98}
car::vif(m)
```



# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
## ROUND 10: Try adding D_Diet_Vegan back in
#### Fit of model is similar to current best fit, but goodness of fit test now fails.
```{r II99}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Therapeutic_Food + D_Diet_Vegan
         + D_Age_quant + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II99a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II100}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r III1}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r III2}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r III3}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r III4}
car::vif(m)
```



# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
## ROUND 11: OK, now try D_Diet_Raw
```{r III5}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Therapeutic_Food + D_Diet_Raw
         + D_Age_quant + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r III5a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r III6}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r III7}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r III8}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r III9}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r III10}
car::vif(m)
```




# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
## ROUND 12: Try adding D_Diet_Vegan_Veggie back in
#### Does not improve the overall fit of the model (similar BIC) and fails goodness of fit tests
```{r III11}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Therapeutic_Food + D_Diet_Vegan_Veggie
         + D_Age_quant + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r III11a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r III12}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r III13}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r III14}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r III15}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r III16}
car::vif(m)
```



# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
## SO THIS IS THE LIKELY TO BE THE FINAL BEST FIT MODEL FOR BINARY LOGISTIC REGRESSION
```{r III17}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Therapeutic_Food 
         + D_Age_quant + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=9)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r III17a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r III18}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r III19}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r III20}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r III21}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r III22}
car::vif(m)
```



# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION BASED ON BIC
## SO THIS IS THE FINAL BEST FIT MODEL FOR BINARY LOGISTIC REGRESSION
### just check that all variables are needed... first remove D_Age_quant
```{r III23}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Therapeutic_Food 
         + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=9)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r III23a}
NagelkerkeR2(m)
```



# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION BASED ON BIC
## SO THIS IS THE FINAL BEST FIT MODEL FOR BINARY LOGISTIC REGRESSION
#### just check that all variables are needed... next remove Visits
```{r III24}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Therapeutic_Food 
         + D_Age_quant + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=9)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

#### Calculate Nagelkerke R^2
```{r III24a}
NagelkerkeR2(m)
```



# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION BASED ON BIC
## SO THIS IS THE FINAL BEST FIT MODEL FOR BINARY LOGISTIC REGRESSION
### just check that all variables are needed... now, try removing Meds
```{r III25}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ Therapeutic_Food 
         + D_Age_quant + Visits, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=9)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r III25a}
NagelkerkeR2(m)
```



# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION BASED ON BIC
## SO THIS IS THE FINAL BEST FIT MODEL FOR BINARY LOGISTIC REGRESSION
### just check that all variables are needed... now, try removing therapeutic food
```{r III26}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ D_Age_quant + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=9)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r III26a}
NagelkerkeR2(m)
```




# DEFINITELY THE BEST FIT FINAL BINARY LOGISTIC REGRESSION MODEL
## MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
### SO THIS IS THE FINAL BEST FIT MODEL FOR BINARY LOGISTIC REGRESSION
```{r III27}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~ D_Age_quant + Visits + Meds + Therapeutic_Food, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r III27a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r III28}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r III29}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r III29a}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r III30}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r III31}
car::vif(m)
```


# Create Figure of best fit model of binary health (healthy only)
```{r}
boxLabels = c("D_Age_quant [3,5]", "D_Age_quant [5,7]", "D_Age_quant [7,9]", "D_Age_quant [9,20]", "Visits 1", "Visits 2", "Visits 3","Visits 4+","Meds", "Therapeutic food")
# Enter OR and CI data. boxOdds are the odds ratios, 
# boxCILow is the lower bound of the CI, boxCIHigh is the upper bound.
df <- data.frame(yAxis = length(boxLabels):1, 
                 boxOdds = c(1.34921677, 1.52124659, 2.44526683, 4.81929850,
                             0.98832681, 2.36017300, 2.55033872, 4.87492360,
                             5.98070804, 2.71053811), 
                 boxCILow = c(0.86704179, 0.96002641, 1.51440366,
                              3.11616979, 0.63155855, 1.43662466,
                              1.35291473, 2.64994667, 4.33257003,
                              1.26345707), 
                 boxCIHigh = c(2.1042664, 2.4148825, 3.9653611,
                               7.5305917, 1.5700942, 3.9254401,
                               4.8643287, 9.1386866, 8.3042615,
                               6.1755184))


# Plot
p <- ggplot(df, aes(x = boxOdds, y = boxLabels)) 

p + geom_vline(aes(xintercept = 1), size = .25, linetype = "dashed") +
  geom_errorbarh(aes(xmax = boxCIHigh, xmin = boxCILow), size = .5, height = 
                   .2, color = "gray50") +
  geom_point(size = 3.5, color = c("blue", "blue", "red", "red","blue", "red", "red", "red", "red", "red")) +
  theme_bw() + 
  theme(panel.grid.minor = element_blank()) +
  theme(panel.grid.major = element_line(size = 0.25)) +
   scale_x_log10(limits = c(0.06,40), breaks = c(0.12, 0.25, 0.5, 1, 2, 4, 8, 16, 32)) +
  ylab("") +
  xlab("\nOdds ratio (log scale)") +
  theme(axis.text = element_text(face="bold")) +
  theme(axis.title.x = element_text(face="bold")) +
  annotate(geom = "text", y =1.0, x = 10.0, label ="Model P < 0.001\nPseudo  R^2 = 0.428",
           size = 3.0, hjust = 0) + ggtitle("Binary logistic regression: any health problem") +
  theme(plot.title = element_text(hjust = 0.5))
ggsave("FigBR_anyHealth.TIFF")
```



# Finally, let's try a model with all variables
```{r III32x}
# fit binary logit model and store results 'm'
m <- glm(Any_Health_Problem ~  Location + setting + Education_S + Animal_Career_BINARY 
         + Income2 + C_Age2 + C_Gender + C_Diet + Size2 + D_Sex + D_Neuter  + D_Diet + Therapeutic_Food + Visits 
         + Meds + D_Age_quant, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r III33x}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r III34x}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r III35x}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r III36x}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Any_Health_Problem), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r III37x}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r III38x}
car::vif(m)
```

```{r}
df2 <- exp(cbind(OR = coef(m), confint(m)))
colnames(df2) <- c("a","b","c")
```




# Create Figure of all-variable model ... Binary logistic regression on Any_Health_Problem
```{r FigBR-anyHlth}

boxLabels = c("Location: Other European","Location: North America","Location: Australia/New Zealand/Oceania","Location: Other","Setting_Rural","Setting_Equally_urban_and_rural","Education_S1_College","Education_S2_Grad","Education_S3_PG_or_PhD","Animal_Career_Yes","Income_Medium","Income_High","C_Age_30-39","C_Age_40-49","C_Age_50-59","C_Age_60+","C_Gender_Male","C_Diet_Omnivore","C_Diet_Pescatarian","C_Diet_Vegan","C_Diet_Vegetarian", "Size_Toy", "Size_Small","Size_Large", "Size_Giant", "D_Sex_Male","Neutered","D_Diet_Raw","D_Diet_Vegan","D_Diet_Vegetarian","Therapeutic food","Visits 1", "Visits 2", "Visits 3", "Visits 4+","Meds","D_Age_quant [3,5]", "D_Age_quant [5,7]", "D_Age_quant [7,9]", "D_Age_quant [9,20]")
# Enter OR and CI data. boxOdds are the odds ratios, 
# boxCILow is the lower bound of the CI, boxCIHigh is the upper bound.
df <- data.frame(yAxis = length(boxLabels):1, 
                 boxOdds = c(1.3223245, 1.2628516, 1.1019348,
                             1.0254744, 1.1423877, 0.9050227,
                             0.8364568, 0.9298961, 0.6855850,
                             0.8542130, 0.8337579, 0.5950873,
                             0.8137338, 0.7497244,0.5123239,
                             0.5545808, 0.7009511, 1.0238247,
                             1.4595393, 0.9216001, 0.8841465,
                             2.0677381, 1.1626869, 1.1075861,
                             2.0466524, 0.9967020, 1.0695262,
                             0.9836356, 0.5405001, 0.7138089,
                             2.6858794, 0.9960722, 2.3550448,
                             2.5184679, 5.0262631, 6.2521264,
                             1.4102688, 1.6194236, 2.7421564, 5.8775695), 
                 boxCILow = c(0.79051298, 0.66640721, 0.50809199,
                              0.39700684, 0.78617776, 0.62261547,
                              0.53683673, 0.59399294, 0.42446958,
                              0.57617095, 0.55175009, 0.34054912,
                              0.49753638, 0.44970090, 0.30718211,
                              0.31825749, 0.38091009, 0.68731791,
                              0.73181249, 0.53265163, 0.51888588,
                              0.78077055, 0.77221824, 0.78116197,
                              0.95259624, 0.73717891, 0.71744929,
                              0.69761287, 0.29278365, 0.20225619,
                              1.22564794, 0.62739571, 1.39966762,
                              1.29962272, 2.65929204, 4.46888342,
                              0.89497829, 1.00228269, 1.65353051, 3.66420150), 
                 boxCIHigh = c(2.2147718, 2.3736753, 2.3824582,
                               2.5622845, 1.6628881, 1.3145363,
                               1.3036060, 1.4575269, 1.1050667,
                               1.2603071, 1.2640286, 1.0352918,
                               1.3311970, 1.2490179, 0.8519477,
                               0.9631637, 1.2545554, 1.5212017,
                               2.9052457, 1.5856194, 1.4945398,
                               5.3339228, 1.7477363, 1.5701855,
                               4.3131974, 1.3477464, 1.6045480,
                               1.3880897, 0.9919101, 2.4438150,
                               6.2694091, 1.6039992, 4.0093278,
                               4.9379835, 9.6811397, 8.8089204,
                               2.2281707, 2.6217715, 4.5733976, 9.5432250))


# Plot
p <- ggplot(df, aes(x = boxOdds, y = boxLabels)) 
p + geom_vline(aes(xintercept = 1), size = .25, linetype = "dashed") +
  geom_errorbarh(aes(xmax = boxCIHigh, xmin = boxCILow), size = .5, height = 
                   .2, color = "gray50") +
  geom_point(size = 1.0, color = c("blue", "blue", "blue", "blue", "blue","blue",
                                   "blue", "blue", "blue", "blue", "blue","blue",
                                   "blue", "blue", "red", "red", "blue","blue",
                                   "blue", "blue", "blue", "blue", "blue","blue",
                                   "blue", "blue", "blue", "blue", "red","blue",
                                   "red", "blue", "red", "red", "red", "red",
                                    "blue", "blue", "red", "red")) +
  theme_bw() +
  theme(panel.grid.minor = element_blank()) +
  theme(panel.grid.major = element_line(size = 0.25)) +
  scale_x_log10(limits = c(0.007, 40), breaks = c(0.015, 0.03, 0.06, 0.12, 0.25, 0.5, 1, 2, 4, 8, 16, 32)) +
  ylab("") +
  xlab("\nOdds ratio (log scale)") +
  theme(axis.text = element_text(face="bold")) +
    theme(axis.text.y = element_text(size = 4.0)) +
      theme(axis.text.x = element_text(size = 4.0)) +
  theme(axis.title.x = element_text(face="bold", size =6.0)) +
  annotate(geom = "text", y = 2, x = 5.0, label ="Model P < 0.001\nPseudo  R^2 = 0.453", size = 1.8, hjust = 0) +
  ggtitle("Binary logistic regression: any health problem") +
  theme(plot.title = element_text(hjust = 0.5, size = 8)) +
  theme(aspect.ratio= 1.25)


ggsave("FigBRanyHlthProbAll.TIFF")
```








