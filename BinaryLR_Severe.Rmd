---
title: "R stats for nutrition binary logistic regression"
author: "Alex German"
date: "18 June 2022"
output:
  pdf_document: default
  word_document: default
  html_notebook: default
  html_document:
    df_print: paged
---


# Create data frame for analysis
### NB need to run "Read_data_101.Rtm" first to create dataset
```{r include=FALSE}
knitr::knit("Read_data_101.rmd")
```


# LET'S DO SOME INTIAL TABULATION AND CHI SQUARE TESTS

## Tabulate D_Sex + D_Neuter + D_Diet
```{r 1}
## three way cross tabs (xtabs) and flatten the table
ftable(xtabs(~ D_Sex + D_Neuter + D_Diet, data = ml))
```

## Tabulate D_Neuter + D_Diet
```{r 2}
## two way cross tabs (xtabs) and flatten the table
ftable(xtabs(~ D_Neuter + D_Diet, data = ml))
```

## Tabulate C_Diet_Vegan + D_Diet_Vegan
```{r 3}
## two way cross tabs (xtabs) and flatten the table
ftable(xtabs(~ C_Diet_Vegan + D_Diet_Vegan, data = ml))
```

# Tabulate C_Diet_Vegan_Veggie + D_Diet_Vegan_Veggie
```{r 4}
## two way cross tabs (xtabs) and flatten the table
ftable(xtabs(~ C_Diet_Vegan_Veggie + D_Diet_Vegan_Veggie, data = ml))
```


## Tabulate D_Sex, D_Neuter and D_Raw
```{r 5}
## three way cross tabs (xtabs) and flatten the table
ftable(xtabs(~ D_Sex + D_Neuter + D_Diet_Raw, data = ml))
```


## Tabulate D_Neuter and D_Raw
```{r 6}
## two way cross tabs (xtabs) and flatten the table
ftable(xtabs(~ D_Neuter + D_Diet_Raw, data = ml))
```


## Chi squared test of C_VEGAN vs D-VEGAN
```{r 7}

table(ml$C_Diet_Vegan, ml$D_Diet_Vegan)
chisq.test(ml$C_Diet_Vegan, ml$D_Diet_Vegan, correct=FALSE)
```


## Chi squared test of NEUTERED vs D-RAW
```{r 8}

table(ml$D_Neuter, ml$D_Diet_Raw)
chisq.test(ml$D_Neuter, ml$D_Diet_Raw, correct=FALSE)
```


## Tabulate Health_Binary and Income
```{r I57}
## three way cross tabs (xtabs) and flatten the table
ftable(xtabs(~ Health_Binary + Income, data = ml))
```


## Chi squared test of Health_Binary and Income
```{r I58}

table(ml$Health_Binary, ml$Income)
chisq.test(ml$Health_Binary, ml$Income, correct=FALSE)
```





# BINARY LOGISTIC REGRESSION ON SIGNIFICANT OR SERIOUS ILLNESS
## CHECK EFFECT OF OWNER CHARACTERISTICS - simple binary logistic regression

## CLIENT DIET binary regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r 9g}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ C_Diet, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 9ag}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r 10g}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 11g}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 1g2}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 13g}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### Calculate Nagelkerke R^2
```{r g}
NagelkerkeR2(m)
```



## CLIENT DIET VEGAN binary regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r 9}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ C_Diet_Vegan, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 9a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r 10}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 11}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 12}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 13}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### Calculate Nagelkerke R^2
```{r}
NagelkerkeR2(m)
```



## C_Diet_Vegan_Veggie Binary logistic regression for HEALTH
```{r I84}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ C_Diet_Vegan_Veggie, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I84a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I85}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I86}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I87}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I88}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## LOCATION binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r I9}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Location, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
glmtoolbox::hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I9a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I10}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I11}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I12}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I13}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## SETTING binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r I14}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ setting, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
glmtoolbox::hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I14a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I15}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I16}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I17}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I18}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## URBAN binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r I19}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Urban, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I19a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I20}
plot(m, which = 4, id.n = 3)
```

# Extract model results and display data for top 3 values using Cook's distance
```{r I21}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I22}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I23}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## LOCATION + URBAN binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r I24}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Location + Urban, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I24a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I25}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I26}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I27}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I28}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r I29}
car::vif(m)
```



## LOCATION * URBAN binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r I30}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Location*Urban, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I30a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I31}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I32}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I33}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I34}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r I35}
car::vif(m)
```



## EDUCATION Binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r I37}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Education, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```
### Calculate Nagelkerke R^2
```{r I37a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I38}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I39}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I40}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I41}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## EDUCATION_S Binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r I42}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Education_S, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=3)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I42a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I43}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I44}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I45}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I46}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## EDUCATION_S2 Binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r I42i}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Education_S2, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=3)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I42ai}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I43i}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I44i}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I45i}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I46i}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## ANIMAL CAREER 2 Binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r I47}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Animal_Career2, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I47a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I48}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I49}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I50}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

# Filter potential influential data points with abs(.std.res) > 3:
```{r I51}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## ANIMAL_CAREER_BINARY Binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r I52}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Animal_Career_BINARY, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)

## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I52a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I53}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I54}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I55}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I56}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## INCOME Binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r I59}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Income, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
glmtoolbox::hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I59a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I60}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I61}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I62}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I63}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## INCOME2 Binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r I59i}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Income2, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
glmtoolbox::hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I59ai}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I60i}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I61i}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I62i}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I63i}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## C_AGE Binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r I64}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ C_Age, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=4)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I64a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I65}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I66}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I67}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I68}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## C_AGE2 Binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r I64i}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ C_Age2, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=4)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

## Calculate Nagelkerke R^2
```{r I64ai}
NagelkerkeR2(m)
```

## check assumptions of model
#### Cook's distance
```{r I65i}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I66i}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I67i}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I68i}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## C_GENDER Binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r I69}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ C_Gender, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I69a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I70}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I71}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I72}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I73}
model.data %>% 
  filter(abs(.std.resid) > 3)
```




# NOW CHECK ASSOCIATIONS BETWEEN SIGNIFICANT OR SERIOUS ILLNESS AND DOG CHARACTERISTICS - simple BINARY LOGISTIC regression


## DOG DIET VEGAN binary regression for ON SIGNIFICANT OR SERIOUS ILLNESS
```{r 14t}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ D_Diet_Vegan, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 14at}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r 15t}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 16t}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 17t}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 18t}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## DOG DIET binary regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r 14it}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ D_Diet, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 14ati}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r 15ti}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 16ti}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 17ti}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 18ti}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## CLIENT DIET VEGAN + DOG DIET VEGAN binaryl regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r 25sq}
# fit binary logit model and store results 'm2'
m <- glm(Health_Binary ~ C_Diet_Vegan + D_Diet_Vegan, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
glmtoolbox::hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 25asq}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r 26sq}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 27sq}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 28sq}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 29sq}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r 30sq}
car::vif(m)
```



## CLIENT DIET VEGAN * DOG DIET VEGAN binaryl regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r 25s}
# fit binary logit model and store results 'm2'
m <- glm(Health_Binary ~ C_Diet_Vegan*D_Diet_Vegan, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
glmtoolbox::hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 25as}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r 26s}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 27s}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 28s}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 29s}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r 30s}
car::vif(m)
```



## DOG DIET RAW binary regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r 32d}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ D_Diet_Raw, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 32ad}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r 33d}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 34d}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

# plot standardised residuals
```{r 35d}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 36d}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## DOG DIET + CLIENT DIET binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r 78}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ D_Diet + C_Diet , data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=7)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 78a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r 79}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 80}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 81}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 82}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r 89}
car::vif(m)
```



## THERAPEUTIC DIET binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r 90}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Therapeutic_Food, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)

## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 90a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r 91}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 92}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 93}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 94}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## DOG DIET + THERAPEUTIC DIET binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r 95}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ D_Diet + Therapeutic_Food, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=3)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 95a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r 96}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 97}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 98}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 99}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r I1}
car::vif(m)
```



## DOG DIET * THERAPEUTIC DIET binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r I2}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ D_Diet*Therapeutic_Food, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=7)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I2a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I3}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I4}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I6}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I7}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
##### Note interactions
```{r I8}
car::vif(m)
```



## SIZE Binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r I89}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Size, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### check assumptions of model
#### Cook's distance
```{r I90}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I91}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I92}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I93}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## SIZE2 Binary logistic regression for HEALTH
```{r I89i}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Size2, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I89iii}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I90i}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I91i}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I92i}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I93i}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## SIZE_GIANT Binary logistic regression for HEALTH
```{r I89ii}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Size_Giant, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)

## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I89iv}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r I90ii}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I91ii}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I92ii}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I93ii}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## D_AGE Binary logistic regression for HEALTH
```{r I94}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ D_Age, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r I94a}
NagelkerkeR2(m)
```

### Check age is linear with logit of outcome
##### Note lack of linearity
```{r I95}
ypred = predict(m)
res = residuals(m, type = 'deviance')
plot(ypred,res)
```

### Box Tidwell test to check that D_Age is linearly associated with the logit of the outcome
##### suggests not linear
```{r I96}
boxTidwell(ml$Health_Binary ~ ml$D_Age)
```

### check assumptions of model
#### Cook's distance
```{r I97}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r I98}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r I99}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r I100}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## D_Age_quant logistic regression for HEALTH
#### Note better model fit that D_Age
```{r II1}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ D_Age_quant, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=4)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II1aa}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II1a}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II2}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II3}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II4}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## D_SEX Binary logistic regression for HEALTH
```{r II17}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ D_Sex, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II17a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II18}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II19}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II20}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II21}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## DOG NEUTER binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r 37d}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ D_Neuter, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r 37ad}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r 38d}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r 39d}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r 40d}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r 41d}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## D_SEX + D_NEUTER Binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r II5}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ D_Sex + D_Neuter, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II5a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II6}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II7}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II8}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II9}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II10}
car::vif(m)
```



## D_SEX * D_NEUTER Binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r II11}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ D_Sex*D_Neuter, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II11a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II12}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II13}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

# plot standardised residuals
```{r II14}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

# Filter potential influential data points with abs(.std.res) > 3:
```{r II15}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II16}
car::vif(m)
```




# CHECK EFFECT OF DOG HEALTH CHARACTERISTICS ON SIGNIFICANT OR SERIOUS ILLNESS - simple binary regression

## THERAPEUTIC FOOD Binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r II27}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Therapeutic_Food, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)

## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II27a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II28}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II29}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II30}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II31}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## VISITS Binary logistic regression ON SIGNIFICANT OR SERIOUS ILLNESS
```{r II32}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Visits, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II32a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II33}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II34}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II35}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II36}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## VISITS2 Binary logistic regression for HEALTH
#### Note Visits better fit than Visits2
```{r II37}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Visits2, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II37a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II37aa}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II38}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II39}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II40}
model.data %>% 
  filter(abs(.std.resid) > 3)
```



## MEDS Binary logistic regression for HEALTH
```{r II41}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test

## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II41a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II42}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II43}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II44}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II45}
model.data %>% 
  filter(abs(.std.resid) > 3)
```




# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
## ROUND 1a: All models of significance on simple regression
### D_Age included as quantiles and Animal Career as a binary

```{r II46}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Location + D_Diet + Therapeutic_Food + Animal_Career_BINARY + C_Diet + D_Age_quant + Size2 + D_Neuter + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II46a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II47}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II48}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II49}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II50}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II51}
car::vif(m)
```




## MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
### ROUND 2: Remove D_Diet as least significant variable in round 1
```{r II52}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Location + Therapeutic_Food + Animal_Career_BINARY + C_Diet + Size2 + D_Age_quant + D_Neuter + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```
### Calculate Nagelkerke R^2
```{r II52a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II53}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II54}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II55}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II56}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II57}
car::vif(m)
```



## MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
### ROUND 3: Remove Neuter as least significant variable in round 2
```{r II58}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Location + Therapeutic_Food + Animal_Career_BINARY + C_Diet + Size2+ D_Age_quant + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II58a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II59}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II60}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II61}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II62}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II63}
car::vif(m)
```



## MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
### ROUND 4a: Remove Animal_Career_Binary as least significant variable in round 3
```{r II64}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Location + Therapeutic_Food + C_Diet + Size2 + D_Age_quant + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II64a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II65}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II66}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II67}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II68}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II68a}
car::vif(m)
```


# MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
### ROUND 4b: Try without Location as most regions are not significant in round 4a

```{r II46u}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Therapeutic_Food + C_Diet + Size2 + D_Age_quant + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II46au}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II47u}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II48u}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II49u}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II50u}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II51u}
car::vif(m)
```




## MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
### ROUND 5a: Remove Size2 as least significant variable in round 4
```{r II69i}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Therapeutic_Food + D_Age_quant + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```
### Calculate Nagelkerke R^2
```{r II69ai}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II70i}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II71i}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II72i}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II73i}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II74i}
car::vif(m)
```



## MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
### ROUND 5b: Add Size_Giant to see if improves fit from round 5a
```{r II69ii}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Therapeutic_Food + Size_Giant + D_Age_quant + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```
### Calculate Nagelkerke R^2
```{r II69aii}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II70ii}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II71ii}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II72ii}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

# Filter potential influential data points with abs(.std.res) > 3:
```{r II73ii}
model.data %>% 
  filter(abs(.std.resid) > 3)
```


# check for multicollinearity
```{r II74ii}
car::vif(m)
```







## MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
### ROUND 6.  Remove Therapeutic_Food as least significant variable in round 5
```{r II75}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ D_Age_quant + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m, G=9)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II75a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II76}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II77}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II78}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II79}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II80}
car::vif(m)
```



## MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
### ROUND 7: Try interactions between age and Visits
```{r II81}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ D_Age_quant*Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II81a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II82}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II83}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II84}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II85}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II86}
car::vif(m)
```



## MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
### ROUND 8: Now try interactions between age and Meds
```{r II87}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ D_Age_quant*Meds + Visits, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II87a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II88}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II89}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II90}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II91}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II92}
car::vif(m)
```



## MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
### ROUND 9: Now try adding D_Diet back in
```{r II93}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ D_Age_quant + Visits + Meds + D_Diet, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II93a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II94}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r II95}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r II96}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r II97}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r II98}
car::vif(m)
```


## MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
### ROUND 10: Try adding D_Raw in instead
```{r II99}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ D_Age_quant + Visits + Meds + D_Diet_Raw, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r II99a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r II100}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r III1}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r III2}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r III3}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r III4}
car::vif(m)
```




## MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
### ROUND 11: OK, now try D_Diet_Vegan
```{r III5}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ D_Age_quant + Visits + Meds + D_Diet_Vegan, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r III5a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r III6}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r III7}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r III8}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r III9}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r III10}
car::vif(m)
```



## MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
### ROUND 12: Try adding D_Diet_Vegan_Veggie back in
```{r III11}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ D_Age_quant + Visits + Meds + D_Diet_Vegan_Veggie, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r III11a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r III12}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r III13}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r III14}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r III15}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r III16}
car::vif(m)
```



## MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
### ROUND 12: Try adding Size_Giant back in
```{r III11i}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ D_Age_quant + Visits + Meds + Size_Giant, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r III11ai}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r III12i}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r III13i}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r III14i}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r III15i}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r III16i}
car::vif(m)
```



## MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION
### SO THIS IS THE FINAL BEST FIT MODEL FOR BINARY LOGISTIC REGRESSION
```{r III17}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~  D_Age_quant + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r III17a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r III18}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r III19}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r III20}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r III21}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r III22}
car::vif(m)
```



## MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION BASED ON BIC
### SO THIS IS THE FINAL BEST FIT MODEL FOR BINARY LOGISTIC REGRESSION
#### just check that all variables are needed... first remove D_Age_quant
```{r III23}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~ Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r III23a}
NagelkerkeR2(m)
```



## MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION BASED ON BIC
### SO THIS IS THE FINAL BEST FIT MODEL FOR BINARY LOGISTIC REGRESSION
#### just check that all variables are needed... next remove Visits
```{r III24}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~  D_Age_quant + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r III24a}
NagelkerkeR2(m)
```



## MULTIPLE REGRESSION WITH BACKWARDS ELIMINATION BASED ON BIC
### SO THIS IS THE FINAL BEST FIT MODEL FOR BINARY LOGISTIC REGRESSION
### just check that all variables are needed... finally, try removing Meds
```{r III25}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~  D_Age_quant + Visits, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```
### Calculate Nagelkerke R^2
```{r III25a}
NagelkerkeR2(m)
```



## DEFINITELY THE BEST FIR FINAL BINARY LOGISTIC REGRESSION MODEL



### SO THIS IS THE FINAL BEST FIT MODEL FOR BINARY LOGISTIC REGRESSION
```{r III26}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~  D_Age_quant + Visits + Meds, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r III26a}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r III27}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r III28}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r III29}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r III30}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r III31}
car::vif(m)
```



# Create Figure of best fit model
```{r}
boxLabels = c("D_Age_quant [3,5]", "D_Age_quant [5,7]", "D_Age_quant [7,9]", "D_Age_quant [9,20]", "Visits 1", "Visits 2", "Visits 3","Visits 4+","Meds")
# Enter OR and CI data. boxOdds are the odds ratios, 
# boxCILow is the lower bound of the CI, boxCIHigh is the upper bound.
df <- data.frame(yAxis = length(boxLabels):1, 
                 boxOdds = c(1.699113835, 1.982752726, 2.251117508,
                             4.725847087, 0.383497720, 0.620903065,
                             1.186373724, 4.753588280, 9.401499065), 
                 boxCILow = c(0.6016241889, 0.7094305253, 0.8362614376,
                              2.0475624431, 0.0855812163, 0.1448269611,
                              0.2597716745, 1.2263716693, 3.4702554750), 
                 boxCIHigh = c(4.94641756, 5.74959921, 6.38470928,
                               12.18534914, 2.04637268, 3.33437256,
                               6.64748195, 24.30630824, 31.49805490))


# Plot
p <- ggplot(df, aes(x = boxOdds, y = boxLabels)) 

p + geom_vline(aes(xintercept = 1), size = .25, linetype = "dashed") +
  geom_errorbarh(aes(xmax = boxCIHigh, xmin = boxCILow), size = .5, height = 
                   .2, color = "gray50") +
  geom_point(size = 3.5, color = c("blue", "blue", "blue", "red", "blue", "blue", "blue", "red", "red")) +
  theme_bw() +
  theme(panel.grid.minor = element_blank()) +
  theme(panel.grid.major = element_line(size = 0.25)) +
   scale_x_log10(limits = c(0.06,40), breaks = c(0.12, 0.25, 0.5, 1, 2, 4, 8, 16, 32)) +
  ylab("") +
  xlab("\nOdds ratio (log scale)") +
  theme(axis.text = element_text(face="bold")) +
  theme(axis.title.x = element_text(face="bold")) +
  annotate(geom = "text", y =1.0, x = 10.0, label ="Model P < 0.001\nPseudo  R^2 = 0.349",
           size = 3.0, hjust = 0) + ggtitle("Binary logistic regression: significant illness") +
   theme(plot.title = element_text(hjust = 0.5))

ggsave("FigBR_SigSeriousILL.TIFF")
```




# Finally, let's try a model with all variables
```{r III32}
# fit binary logit model and store results 'm'
m <- glm(Health_Binary ~  Location + setting + Education_S2 + Animal_Career_BINARY 
         + Income2 + C_Age2 + C_Gender + C_Diet + Size2 + D_Sex + D_Neuter  + D_Diet + Therapeutic_Food + Visits 
         + Meds + D_Age_quant, data = ml,family = binomial)
# view a summary of the model
summary(m)
# test model fit
with(m, null.deviance - deviance)
with(m, df.null - df.residual)
with(m, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
BIC(m)
# Hosmer-Lemeshow Goodness-of-Fit Test
hltest(m)
## CIs using profiled log-likelihood
confint(m, level=0.99)
## CIs using standard errors
confint.default(m, level=0.99)
# Wald test
wald.test(b = coef(m), Sigma = vcov(m), Terms = 2)
## odds ratios and 95% CI
exp(cbind(OR = coef(m), confint(m, level=0.99)))
```

### Calculate Nagelkerke R^2
```{r III33}
NagelkerkeR2(m)
```

### check assumptions of model
#### Cook's distance
```{r III34}
plot(m, which = 4, id.n = 3)
```

#### Extract model results and display data for top 3 values using Cook's distance
```{r III35}
model.data <- augment(m) %>% 
  mutate(index = 1:n()) 
model.data %>% top_n(3, .cooksd)
```

#### plot standardised residuals
```{r III36}
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Health_Binary), alpha = .5) +
  theme_bw()
```

#### Filter potential influential data points with abs(.std.res) > 3:
```{r III37}
model.data %>% 
  filter(abs(.std.resid) > 3)
```

#### check for multicollinearity
```{r III38}
car::vif(m)
```



# Create Figure of all-variable model ... Binary logistic regression on Significnt or serious illness
```{r FigBR-anyHlth}

boxLabels = c("Location: Other European","Location: North America","Location: Australia/New Zealand/Oceania","Location: Other","Setting_Rural","Setting_Equally_urban_and_rural","Education_S1_College","Education_S2_Grad","Education_S3_PG_or_PhD","Animal_Career_Yes","Income_Medium","Income_High","C_Age_30-39","C_Age_40-49","C_Age_50-59","C_Age_60+","C_Gender_Male","C_Diet_Omnivore","C_Diet_Pescatarian","C_Diet_Vegan","C_Diet_Vegetarian", "Size_Toy", "Size_Small","Size_Large", "Size_Giant", "D_Sex_Male","Neutered","D_Diet_Raw","D_Diet_Vegan","D_Diet_Vegetarian","Therapeutic food","Visits 1", "Visits 2", "Visits 3", "Visits 4+","Meds","D_Age_quant [3,5]", "D_Age_quant [5,7]", "D_Age_quant [7,9]", "D_Age_quant [9,20]")
# Enter OR and CI data. boxOdds are the odds ratios, 
# boxCILow is the lower bound of the CI, boxCIHigh is the upper bound.
df <- data.frame(yAxis = length(boxLabels):1, 
                 boxOdds = c(2.161618919, 1.565590759, 1.117315934,
                             1.133815004, 1.306755449, 0.832845818,
                             0.509049547, 1.022553709, 0.604411061,
                             1.376167572, 0.898250909, 0.540292441,
                             1.437153692, 0.835348042, 1.395351559,
                             0.929109771, 1.029611667, 1.545151412,
                             0.286699419, 0.942815461, 1.635412971,
                             0.743734286, 0.839041459, 1.483042250,
                             4.825742736, 0.675955838, 0.801365617,
                             0.914971027, 0.807614074, 1.086785867,
                             2.010517094, 0.369671097, 0.624925479,
                             1.351662954, 5.647954052, 9.514138586,
                             1.714361926, 2.119367995, 2.124089551,5.402455224), 
                 boxCILow = c(0.8637618494, 0.4497971406, 0.2760027505,
                              0.1641846525, 0.6316212015, 0.3863808235,
                              0.2044781842, 0.4425046828, 0.2488545182,
                              0.6613646507, 0.4209362175, 0.1747680871,
                              0.5463101990, 0.2888749642, 0.5012349129,
                              0.2999330388, 0.2587978071, 0.7114326839,
                              0.0343527298, 0.3342357392, 0.6056494596,
                              0.0088219511, 0.3466071462, 0.7565813345,
                              1.1925406514, 0.3714333167, 0.3213290780,
                              0.4257370379, 0.2430641861, 0.1042443297,
                              0.8233545448, 0.0765911937, 0.1350002523,
                              0.2725792768, 1.3146989451, 3.4693726814,
                              0.5623880523, 0.6967787398, 0.7182960340, 2.0915352518), 
                 boxCIHigh = c(5.24887038, 4.66305739, 3.81945489,
                               5.52088770, 2.71402037, 1.77355185,
                               1.25176188, 2.40771540, 1.46755001,
                               2.78790943, 2.03272505, 1.60047681,
                               4.00284138, 2.46770617, 4.09123366,
                               2.96313609, 3.28026864, 3.34158298,
                               1.31200398, 2.54198309, 4.19020885,
                               7.02115490, 1.94271331, 2.95087732,
                               17.52334540, 1.22094570, 2.19579119,
                               1.88554579, 2.54461513, 7.33326613,
                               4.73940073, 2.08300407, 3.51355463,
                               7.98909224, 30.88691763, 32.10242149,
                               5.39245834, 6.70047139, 6.60937186, 15.55558934))


# Plot
p <- ggplot(df, aes(x = boxOdds, y = boxLabels)) 
p + geom_vline(aes(xintercept = 1), size = .25, linetype = "dashed") +
  geom_errorbarh(aes(xmax = boxCIHigh, xmin = boxCILow), size = .5, height = 
                   .2, color = "gray50") +
  geom_point(size = 1.0, color = c("blue", "blue", "blue", "blue", "blue","blue",
                                   "blue", "blue", "blue", "blue", "blue","blue",
                                   "blue", "blue", "blue", "blue", "blue","blue",
                                   "blue", "blue", "blue", "blue", "blue","blue",
                                   "red", "blue", "blue", "blue", "blue","blue",
                                   "blue", "blue", "blue", "blue", "red", "red",
                                    "blue", "blue", "blue", "red")) +
  theme_bw() +
  theme(panel.grid.minor = element_blank()) +
  theme(panel.grid.major = element_line(size = 0.25)) +
  scale_x_log10(limits = c(0.007, 40), breaks = c(0.015, 0.03, 0.06, 0.12, 0.25, 0.5, 1, 2, 4, 8, 16, 32)) +
  ylab("") +
  xlab("\nOdds ratio (log scale)") +
  theme(axis.text = element_text(face="bold")) +
    theme(axis.text.y = element_text(size = 4.0)) +
      theme(axis.text.x = element_text(size = 4.0)) +
  theme(axis.title.x = element_text(face="bold", size =6.0)) +
  annotate(geom = "text", y = 2, x = 5.0, label ="Model P < 0.001\nPseudo  R^2 = 0.410", size = 1.8, hjust = 0) +
  ggtitle("Binary logistic regression: significant illness") +
  theme(plot.title = element_text(hjust = 0.5, size = 8)) +
  theme(aspect.ratio= 1.25)


ggsave("FigBRSigSerAll.TIFF")
```




